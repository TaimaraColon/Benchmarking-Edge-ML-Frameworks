{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PyTorch Deployment Optimization Report: CUDA Migration**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial deep learning benchmarking script was found to be running exclusively on the CPU, severely limiting performance gains intended for GPU acceleration. Root cause analysis confirmed that the deployed PyTorch package was the CPU-only distribution (`2.6.0+cpu`). The issue was successfully resolved by uninstalling the CPU version and installing the correct CUDA-enabled PyTorch build, specifically targeting CUDA 11.7."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Problem Identification**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided benchmarking script correctly implemented a device check using `torch.cuda.is_available()`, but the global configuration defaulted to CPU:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TARGET_DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following script shows the version installation of PyTorch (if cuda supported or not):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PyTorch and CUDA Setup Diagnosis ---\n",
      "PyTorch Version: 2.0.1+cu117\n",
      "Python Version: 3.9.13\n",
      "----------------------------------------\n",
      "PyTorch built with CUDA version: 11.7\n",
      "torch.cuda.is_available(): True\n",
      "----------------------------------------\n",
      "Number of GPUs detected: 1\n",
      "GPU 0 Name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "GPU 0 Capability: (8, 6)\n",
      "Total Memory: 6.00 GB\n",
      "----------------------------------------\n",
      "torch.backends.cudnn.is_available(): True\n",
      "Test tensor successfully moved to device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "def check_cuda_setup():\n",
    "    \"\"\"Checks the PyTorch and CUDA installation status.\"\"\"\n",
    "    \n",
    "    print(\"--- PyTorch and CUDA Setup Diagnosis ---\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check 1: Is PyTorch built with CUDA support?\n",
    "    # This checks which CUDA version PyTorch was compiled against.\n",
    "    cuda_build_version = torch.version.cuda\n",
    "    print(f\"PyTorch built with CUDA version: {cuda_build_version}\")\n",
    "    \n",
    "    # Check 2: Is CUDA currently available for use?\n",
    "    cuda_is_available = torch.cuda.is_available()\n",
    "    print(f\"torch.cuda.is_available(): {cuda_is_available}\")\n",
    "\n",
    "    if not cuda_is_available:\n",
    "        print(\"\\n\\t*** DIAGNOSIS: CUDA is NOT available to PyTorch. ***\")\n",
    "        print(\"\\tCheck your PyTorch installation (did you use the CUDA version?)\")\n",
    "        print(\"\\tCheck your NVIDIA drivers and CUDA Toolkit installation.\")\n",
    "        return\n",
    "\n",
    "    # If CUDA is available, check GPU details\n",
    "    print(\"-\" * 40)\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs detected: {gpu_count}\")\n",
    "    \n",
    "    if gpu_count > 0:\n",
    "        for i in range(gpu_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            print(f\"GPU {i} Name: {gpu_name}\")\n",
    "            print(f\"GPU {i} Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "            print(f\"Total Memory: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.2f} GB\")\n",
    "    \n",
    "    # Check 3: CuDNN status (often used for performance)\n",
    "    cudnn_is_available = torch.backends.cudnn.is_available()\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"torch.backends.cudnn.is_available(): {cudnn_is_available}\")\n",
    "\n",
    "    if cuda_is_available and gpu_count > 0:\n",
    "        # Final check: can we move a tensor to the device?\n",
    "        try:\n",
    "            test_tensor = torch.randn(2, 2).to('cuda:0')\n",
    "            print(f\"Test tensor successfully moved to device: {test_tensor.device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to move test tensor to GPU: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    check_cuda_setup()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Resolution**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resolution involved a two-step migration to the correct PyTorch distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.1: Package Removal**\n",
    "\n",
    "The previous CPU-only packages were uninstalled from the environment:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip uninstall torch torchvision torchaudio`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.2: CUDA-Enabled Installation**\n",
    "\n",
    "A targeted `pip` installation was performed using the official PyTorch download index for CUDA 11.7. This command fetches the pre-compiled binary that includes the necessary hooks for GPU acceleration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Command Used for Resolution:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip3 install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu117](https://download.pytorch.org/whl/cu117)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Conclusion**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the reinstallation, the diagnostic check now confirms `torch.cuda.is_available(): True`. The original benchmarking script is now running on the specified CUDA device (`cuda:0`). This migration enables the expected high-performance inference and allows for accurate measurement of dynamic metrics like throughput and latency under true GPU operating conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7edcbd51d003786adb1b4e1f80280b9023b7f40ffcc7c654fe654e28bb9b8e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
