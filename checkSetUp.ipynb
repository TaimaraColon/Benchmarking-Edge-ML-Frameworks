{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PyTorch and CUDA Setup Diagnosis ---\n",
      "PyTorch Version: 2.0.1+cu117\n",
      "Python Version: 3.9.13\n",
      "----------------------------------------\n",
      "PyTorch built with CUDA version: 11.7\n",
      "torch.cuda.is_available(): False\n",
      "\n",
      "\t*** DIAGNOSIS: CUDA is NOT available to PyTorch. ***\n",
      "\tCheck your PyTorch installation (did you use the CUDA version?)\n",
      "\tCheck your NVIDIA drivers and CUDA Toolkit installation.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "def check_cuda_setup():\n",
    "    \"\"\"Checks the PyTorch and CUDA installation status.\"\"\"\n",
    "    \n",
    "    print(\"--- PyTorch and CUDA Setup Diagnosis ---\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check 1: Is PyTorch built with CUDA support?\n",
    "    # This checks which CUDA version PyTorch was compiled against.\n",
    "    cuda_build_version = torch.version.cuda\n",
    "    print(f\"PyTorch built with CUDA version: {cuda_build_version}\")\n",
    "    \n",
    "    # Check 2: Is CUDA currently available for use?\n",
    "    cuda_is_available = torch.cuda.is_available()\n",
    "    print(f\"torch.cuda.is_available(): {cuda_is_available}\")\n",
    "\n",
    "    if not cuda_is_available:\n",
    "        print(\"\\n\\t*** DIAGNOSIS: CUDA is NOT available to PyTorch. ***\")\n",
    "        print(\"\\tCheck your PyTorch installation (did you use the CUDA version?)\")\n",
    "        print(\"\\tCheck your NVIDIA drivers and CUDA Toolkit installation.\")\n",
    "        return\n",
    "\n",
    "    # If CUDA is available, check GPU details\n",
    "    print(\"-\" * 40)\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs detected: {gpu_count}\")\n",
    "    \n",
    "    if gpu_count > 0:\n",
    "        for i in range(gpu_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            print(f\"GPU {i} Name: {gpu_name}\")\n",
    "            print(f\"GPU {i} Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "            print(f\"Total Memory: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.2f} GB\")\n",
    "    \n",
    "    # Check 3: CuDNN status (often used for performance)\n",
    "    cudnn_is_available = torch.backends.cudnn.is_available()\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"torch.backends.cudnn.is_available(): {cudnn_is_available}\")\n",
    "\n",
    "    if cuda_is_available and gpu_count > 0:\n",
    "        # Final check: can we move a tensor to the device?\n",
    "        try:\n",
    "            test_tensor = torch.randn(2, 2).to('cuda:0')\n",
    "            print(f\"Test tensor successfully moved to device: {test_tensor.device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to move test tensor to GPU: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    check_cuda_setup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7edcbd51d003786adb1b4e1f80280b9023b7f40ffcc7c654fe654e28bb9b8e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
